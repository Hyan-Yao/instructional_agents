\documentclass[aspectratio=169]{beamer}

% Theme and Color Setup
\usetheme{Madrid}
\usecolortheme{whale}
\useinnertheme{rectangles}
\useoutertheme{miniframes}

% Additional Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usetikzlibrary{positioning}
\usepackage{hyperref}

% Custom Colors
\definecolor{myblue}{RGB}{31, 73, 125}
\definecolor{mygray}{RGB}{100, 100, 100}
\definecolor{mygreen}{RGB}{0, 128, 0}
\definecolor{myorange}{RGB}{230, 126, 34}
\definecolor{mycodebackground}{RGB}{245, 245, 245}

% Set Theme Colors
\setbeamercolor{structure}{fg=myblue}
\setbeamercolor{frametitle}{fg=white, bg=myblue}
\setbeamercolor{title}{fg=myblue}
\setbeamercolor{section in toc}{fg=myblue}
\setbeamercolor{item projected}{fg=white, bg=myblue}
\setbeamercolor{block title}{bg=myblue!20, fg=myblue}
\setbeamercolor{block body}{bg=myblue!10}
\setbeamercolor{alerted text}{fg=myorange}

% Set Fonts
\setbeamerfont{title}{size=\Large, series=\bfseries}
\setbeamerfont{frametitle}{size=\large, series=\bfseries}
\setbeamerfont{caption}{size=\small}
\setbeamerfont{footnote}{size=\tiny}

% Title Page Information
\title[Introduction to Basic ML Models]{Chapter 5: Introduction to Basic Machine Learning Models}
\author[J. Smith]{John Smith, Ph.D.}
\institute[University Name]{
  Department of Computer Science\\
  University Name\\
  \vspace{0.3cm}
  Email: email@university.edu\\
  Website: www.university.edu
}
\date{\today}

% Document Start
\begin{document}

\frame{\titlepage}

\begin{frame}[fragile]
    \titlepage
\end{frame}

\begin{frame}[fragile]
    \frametitle{Overview of Chapter 5}
    This chapter aims to introduce students to the fundamental concepts of machine learning (ML) models. 
    As we embark on this exploration, we will uncover how these models operate and why they are crucial in the field of artificial intelligence (AI).
\end{frame}

\begin{frame}[fragile]
    \frametitle{Importance of Understanding Basic ML Models}
    \begin{enumerate}
        \item \textbf{Foundation of AI}: 
        Machine learning models are at the heart of AI applications. Understanding them enables us to harness technology for various tasks, from speech recognition to recommendation systems.

        \item \textbf{Real-World Applications}:
        Everyday interactions with ML models include:
        \begin{itemize}
            \item \textbf{Email Filters}: Separating spam from important emails using classification models.
            \item \textbf{Personal Assistants}: Voice recognition using deep learning models.
            \item \textbf{Recommendation Engines}: Suggestions on platforms like Netflix or Amazon using collaborative filtering.
        \end{itemize}

        \item \textbf{Critical Thinking}:
        Learning about these models encourages critical thinking about their capabilities and limitations. It challenges us to ask:
        \begin{itemize}
            \item How can we improve model performance?
            \item What ethical considerations arise from their use?
        \end{itemize}

        \item \textbf{Diverse ML Techniques}:
        The chapter will cover various ML models, including:
        \begin{itemize}
            \item \textbf{Supervised Learning}: Approaches where the model learns from labeled data (e.g., regression and classification).
            \item \textbf{Unsupervised Learning}: Techniques that look for patterns in unlabeled data (e.g., clustering).
            \item \textbf{Reinforcement Learning}: Where agents learn through trial and error (e.g., game playing).
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points to Emphasize}
    \begin{itemize}
        \item \textbf{Interdisciplinary Nature}: 
        Machine learning draws from statistics, computer science, and domain knowledge.
        \item \textbf{Continuous Development}: 
        The field is rapidly evolving; new models and techniques significantly enhance AI capabilities (e.g., transformers in natural language processing).
        \item \textbf{Ethical Considerations}: 
        It's crucial to understand the impact of ML models on society, including fairness, accountability, and transparency.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Engage with the Concepts}
    \begin{block}{Questions to Ponder}
        \begin{itemize}
            \item What is an example of a situation where a machine learning model could fail, and how could we mitigate that risk?
            \item How do we ensure the data used to train our models is representative of the real world?
        \end{itemize}
    \end{block}
    
    \begin{block}{Ready for Next Step}
        Next, we will delve deeper into understanding the different types of data used in machine learning, laying groundwork for our model discussions in the subsequent slides.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding Data Types - Introduction}
    In machine learning (ML) and artificial intelligence (AI), data is mainly categorized into two types:
    \begin{itemize}
        \item \textbf{Structured Data}
        \item \textbf{Unstructured Data}
    \end{itemize}
    Understanding these types is crucial as they influence model design and performance.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding Data Types - Structured Data}
    \textbf{1. Structured Data}
    \begin{itemize}
        \item \textbf{Definition}: Information organized in a formatted manner, easily searchable in a database.
        \item \textbf{Characteristics}:
        \begin{itemize}
            \item Organized into tables (rows and columns)
            \item Predictable format (e.g., numbers, dates)
            \item Easier to analyze with traditional tools
        \end{itemize}
        \item \textbf{Examples}:
        \begin{itemize}
            \item Customer records in CRM systems
            \item Financial reports in spreadsheets
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding Data Types - Unstructured Data}
    \textbf{2. Unstructured Data}
    \begin{itemize}
        \item \textbf{Definition}: Information with no predefined format, complex and less organized.
        \item \textbf{Characteristics}:
        \begin{itemize}
            \item Lacks specific structure (e.g., text, images, audio)
            \item Often involves large volumes that need specific processing techniques
        \end{itemize}
        \item \textbf{Examples}:
        \begin{itemize}
            \item Social media posts, emails, customer reviews
            \item Images, videos, audio recordings
            \item Sensor data from IoT devices
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Significance of Data Types in AI}
    \textbf{3. Importance of Structured and Unstructured Data}
    \begin{itemize}
        \item \textbf{Structured Data}:
        \begin{itemize}
            \item \textit{Ease of Processing}: Algorithms can directly query and process structured data.
            \item \textit{Predictive Modeling}: Suitable for supervised learning where clear labels exist.
        \end{itemize}
        \item \textbf{Unstructured Data}:
        \begin{itemize}
            \item \textit{Rich Insights}: Offers context and assists in decision-making.
            \item \textit{Natural Language Processing (NLP)}: Vital for chatbots and sentiment analysis.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points and Conclusion}
    \textbf{4. Key Points to Emphasize}
    \begin{itemize}
        \item Choice between structured and unstructured data significantly affects model performance.
        \item Different ML techniques are better suited for each data type.
        \item Enhancing data preparation and feature engineering processes is crucial for effective AI models.
    \end{itemize}

    \textbf{Conclusion}: Recognizing data types enables practitioners to select suitable preprocessing techniques, relevant ML models, and extract meaningful insights.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Illustrative Example}
    \textbf{Example: Retail Company Analyzing Customer Data}
    \begin{itemize}
        \item \textbf{Structured Data}: Numeric sales figures and customer demographics in tables.
        \item \textbf{Unstructured Data}: Video footage of customer interactions for behavioral insights.
    \end{itemize}

    \textbf{Remember}: Leveraging both structured and unstructured data is key for building robust AI applications!
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Machine Learning Concepts}
    % Introduction to Machine Learning Types
    \begin{block}{Introduction}
        Machine learning (ML) can be broadly categorized into three primary types:
        \begin{itemize}
            \item Supervised Learning
            \item Unsupervised Learning
            \item Reinforcement Learning
        \end{itemize}
        Understanding these types is fundamental to grasping broader ML concepts.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{1. Supervised Learning}
    % Explanation of Supervised Learning
    \begin{block}{Definition}
        Involves training a model on a labeled dataset, where the model learns to map inputs to the correct output.
    \end{block}
    
    \begin{itemize}
        \item \textbf{Key Features}:
            \begin{itemize}
                \item Labeled Data
                \item Objective: Minimize prediction error
            \end{itemize}
        
        \item \textbf{Common Examples}:
            \begin{itemize}
                \item Classification (e.g., spam detection)
                \item Regression (e.g., predicting house prices)
            \end{itemize}

        \item \textbf{Use Cases}:
            \begin{itemize}
                \item Image recognition
                \item Financial forecasting
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{2. Unsupervised Learning}
    % Explanation of Unsupervised Learning
    \begin{block}{Definition}
        Focuses on uncovering patterns in data without labeled outputs.
    \end{block}

    \begin{itemize}
        \item \textbf{Key Features}:
            \begin{itemize}
                \item No Labeled Data
                \item Objective: Discover hidden structures
            \end{itemize}

        \item \textbf{Common Examples}:
            \begin{itemize}
                \item Clustering (e.g., customer segmentation)
                \item Dimensionality Reduction (e.g., PCA)
            \end{itemize}

        \item \textbf{Use Cases}:
            \begin{itemize}
                \item Market basket analysis
                \item Anomaly detection
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{3. Reinforcement Learning}
    % Explanation of Reinforcement Learning
    \begin{block}{Definition}
        An agent learns to make decisions by taking actions in an environment to maximize cumulative rewards.
    \end{block}

    \begin{itemize}
        \item \textbf{Key Features}:
            \begin{itemize}
                \item Agent and Environment
                \item Trial and Error Learning
            \end{itemize}

        \item \textbf{Common Examples}:
            \begin{itemize}
                \item Game Playing (e.g., AlphaGo)
                \item Robotics (e.g., obstacle navigation)
            \end{itemize}

        \item \textbf{Use Cases}:
            \begin{itemize}
                \item Autonomous vehicles
                \item Personalized recommendations
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Takeaways}
    % Summary and takeaway questions
    Emphasizing the core differences:
    \begin{itemize}
        \item Supervised Learning = Learning from labeled data
        \item Unsupervised Learning = Identifying patterns without labels
        \item Reinforcement Learning = Learning through rewards and penalties
    \end{itemize}

    \textbf{Takeaway Questions}:
    \begin{enumerate}
        \item How do different types of learning influence our approach to data problems?
        \item What real-world scenarios could benefit from each type of machine learning?
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Analyzing Data Relationships}
    \begin{block}{Understanding Data Relationships}
        Analyzing relationships within datasets is essential in machine learning, as it helps us identify patterns and insights that influence decision-making. By visualizing data and using basic statistical techniques, we can uncover meaningful relationships between variables.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Concepts to Explore}
    \begin{enumerate}
        \item \textbf{Correlation}
            \begin{itemize}
                \item Measures the strength and direction of a linear relationship between two variables
                \item Values range from -1 to 1
                \begin{itemize}
                    \item 1: perfect positive correlation
                    \item -1: perfect negative correlation
                    \item 0: no correlation
                \end{itemize}
                \item \textbf{Example:} Positive correlation between study hours and exam scores
                \item \textbf{Formula:}
                \begin{equation}
                r = \frac{n(\Sigma xy) - (\Sigma x)(\Sigma y)}{\sqrt{[n\Sigma x^2 - (\Sigma x)^2][n\Sigma y^2 - (\Sigma y)^2]}}
                \end{equation}
            \end{itemize}
        
        \item \textbf{Visualization Techniques}
        \begin{itemize}
            \item Scatter Plots: Visualize relationships between two continuous variables
            \item Bar Charts: Compare categorical variables
            \item Heatmaps: Show correlation matrices among multiple variables
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Basic Statistical Techniques}
    \begin{enumerate}
        \item \textbf{Descriptive Statistics}
            \begin{itemize}
                \item Mean, median, mode, and standard deviation provide insights about data distribution
            \end{itemize}
        
        \item \textbf{Hypothesis Testing}
            \begin{itemize}
                \item Use tests (e.g., t-tests) to determine if differences between groups are statistically significant
            \end{itemize}
        
        \item \textbf{Key Questions to Consider}
            \begin{itemize}
                \item What variables show a strong correlation in your dataset?
                \item Are there any unexpected relationships that may lead to interesting insights?
                \item How can data visualization clarify these relationships?
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Implementing Basic ML Models}
    \begin{block}{Overview}
        In this section, we will explore how to construct and evaluate simple machine learning (ML) models using data science tools. The primary aim is to understand the process of creating a model and assessing its accuracy in a practical, hands-on manner.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Steps in Implementing Basic ML Models}
    \begin{enumerate}
        \item \textbf{Define the Problem}:
        \begin{itemize}
            \item Clarify the task (classification vs. regression).
            \item Example: Predicting whether a student will pass based on study hours.
        \end{itemize}

        \item \textbf{Collect and Prepare Data}:
        \begin{itemize}
            \item Gather datasets, handle missing values, normalize data, and split into training/testing sets.
            \item Example: Normalize students' exam scores between 0 and 1.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Steps Continued}
    \begin{enumerate}[resume]
        \item \textbf{Choose a Suitable ML Model}:
        \begin{itemize}
            \item Select models based on task. 
            \begin{itemize}
                \item Linear Regression for regression.
                \item Logistic Regression for binary classification.
                \item Decision Trees for both tasks.
            \end{itemize}
            \item Example: Use a Decision Tree to classify students.
        \end{itemize}

        \item \textbf{Train the Model}:
        \begin{lstlisting}[language=Python]
        from sklearn.model_selection import train_test_split
        from sklearn.tree import DecisionTreeClassifier

        X = data[['study_hours']]
        y = data['pass_fail']
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

        model = DecisionTreeClassifier()
        model.fit(X_train, y_train)
        \end{lstlisting}

        \item \textbf{Evaluate the Model}:
        \begin{itemize}
            \item Assess performance with metrics like accuracy.
            \item Example: Check accuracy of student pass/fail predictions.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}
    \frametitle{Popular ML Tools and Platforms}
    \begin{block}{Introduction}
        Machine Learning (ML) has become more accessible through various user-friendly platforms.
        In this slide, we introduce three popular platforms: \textbf{Google Colab}, \textbf{Jupyter Notebooks}, and \textbf{TensorFlow}.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Google Colab}
    \begin{itemize}
        \item \textbf{What is it?} \\
        Google Colab is a web-based interactive coding environment that allows users to execute Python code in their browser without setup.
        
        \item \textbf{Key Features:}
        \begin{itemize}
            \item Free access to GPUs for running complex ML models.
            \item Integration with Google Drive for seamless saving and sharing.
            \item Comes with popular ML libraries pre-installed.
        \end{itemize}
        
        \item \textbf{Example Use Case:} \\
        Logistic Regression Model in Scikit-learn
    \end{itemize}
    
    \begin{lstlisting}[language=Python]
# Import libraries
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Sample data
X = [[0], [1], [2], [3]]
y = [0, 0, 1, 1]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Create and train model
model = LogisticRegression()
model.fit(X_train, y_train)

# Make predictions
predictions = model.predict(X_test)

# Evaluate accuracy
accuracy = accuracy_score(y_test, predictions)
print('Model accuracy:', accuracy)
    \end{lstlisting}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Jupyter Notebooks and TensorFlow}
    \begin{itemize}
        \item \textbf{Jupyter Notebooks:}
        \begin{itemize}
            \item Provide a flexible interface for live code, equations, visualizations, and text.
            \item Allow interactive output and rich text support.
            \item Support various programming languages through Jupyter kernels.
        \end{itemize}

        \item \textbf{Example Use Case:} \\
        Data Visualization with Matplotlib
    \end{itemize}
    
    \begin{lstlisting}[language=Python]
import matplotlib.pyplot as plt

# Sample data
x = [0, 1, 2, 3, 4]
y = [0, 1, 4, 9, 16]

# Create a plot
plt.plot(x, y)
plt.title('Simple Plot')
plt.xlabel('X-axis')
plt.ylabel('Y-axis')
plt.grid()
plt.show()
    \end{lstlisting}
    
    \begin{itemize}
        \item \textbf{TensorFlow:}
        \begin{itemize}
            \item An open-source library for numerical computation and deep learning.
            \item Ideal for building complex models like neural networks.
            \item Offers scalability and a supportive ecosystem.
        \end{itemize}
        
        \item \textbf{Example Use Case:} \\
        Simple Neural Network for Image Classification
    \end{itemize}
    
    \begin{lstlisting}[language=Python]
import tensorflow as tf
from tensorflow.keras import layers, models

# Define the model
model = models.Sequential()
model.add(layers.Flatten(input_shape=(28, 28)))  # Flattening the input
model.add(layers.Dense(128, activation='relu'))   # Hidden layer
model.add(layers.Dense(10, activation='softmax'))  # Output layer

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    \end{lstlisting}
\end{frame}

\begin{frame}
  \frametitle{Evaluating Model Performance}
  % Overview of model performance evaluation in machine learning
  Evaluating the performance of Machine Learning (ML) models is crucial for assessing their ability to generalize to new, unseen data. Techniques and metrics are used to ensure models deliver reliable outcomes in real-world scenarios.
\end{frame}

\begin{frame}
  \frametitle{Importance of Evaluation}
  \begin{itemize}
    \item \textbf{Model Trust}: Understanding the effectiveness of a model fosters trust in its decisions.
    \item \textbf{Iteration and Improvement}: Evaluation highlights areas for improvement, guiding model refinement.
    \item \textbf{Deployment Readiness}: Validating model performance ensures reliability before deployment.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Key Evaluation Metrics}
  \begin{enumerate}
    \item \textbf{Accuracy}
      \begin{itemize}
        \item Definition: Proportion of true results among total cases.
        \item Formula: 
          \begin{equation}
            \text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}
          \end{equation}
        \item Example: 90 out of 100 cases correct leads to 90\% accuracy.
      \end{itemize}
      
    \item \textbf{Precision}
      \begin{itemize}
        \item Definition: Ratio of correctly predicted positives to total predicted positives.
        \item Formula: 
          \begin{equation}
            \text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}
          \end{equation}
        \item Example: 50 correct out of 70 predictions gives Precision = 0.71.
      \end{itemize}

    \item \textbf{Recall (Sensitivity)}
      \begin{itemize}
        \item Definition: Ratio of correctly predicted positives to all actual positives.
        \item Formula: 
          \begin{equation}
            \text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}
          \end{equation}
        \item Example: If 60 out of 80 actual positives are predicted, Recall = 0.75.
      \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}
  \frametitle{Key Evaluation Metrics (Continued)}
  \begin{enumerate}
    \setcounter{enumi}{3}
    \item \textbf{F1 Score}
      \begin{itemize}
        \item Definition: Harmonic mean of Precision and Recall.
        \item Formula:
          \begin{equation}
            \text{F1 Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
          \end{equation}
        \item Example: For Precision = 0.71 and Recall = 0.75, F1 Score â‰ˆ 0.73.
      \end{itemize}

    \item \textbf{ROC-AUC}
      \begin{itemize}
        \item Definition: A plot illustrating the diagnostic ability of a binary classifier; AUC quantifies model discrimination.
        \item Example: AUC of 0.95 indicates excellent performance.
      \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}
  \frametitle{Techniques for Evaluation}
  \begin{itemize}
    \item \textbf{Cross-Validation}: Splits the dataset into parts to ensure consistent model performance across subsets.
      \begin{itemize}
        \item Example: In k-fold cross-validation, data is divided into k subsets for model training and validation.
      \end{itemize}
      
    \item \textbf{Confusion Matrix}: Describes classification model performance by displaying True Positives, True Negatives, False Positives, and False Negatives.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Key Points to Emphasize}
  \begin{itemize}
    \item \textbf{Choosing the Right Metric}: Depends on the problem context; e.g., in medical diagnosis, Recall may be prioritized.
    \item \textbf{Continuous Evaluation}: Models should be continuously evaluated post-deployment as data drift occurs.
    \item \textbf{Balance}: No single metric is sufficient; multiple metrics provide a comprehensive performance evaluation.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Code Snippet}
  % Example Python code for evaluating model performance using scikit-learn
  \begin{lstlisting}[language=Python]
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Assuming y_true are the true labels and y_pred are the predicted labels
accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)

print(f"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}")
  \end{lstlisting}
\end{frame}

\begin{frame}
  \frametitle{Conclusion}
  Evaluating model performance is a vital step in machine learning. It goes beyond accuracy to encompass a range of metrics to understand the strengths and limitations of models, aiding in creating effective machine learning solutions.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data Sources for AI}
    \begin{block}{Introduction to Data Sources}
        The quality and quantity of data are crucial for the performance of machine learning models. Understanding various data sources is essential for effective AI applications.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Types of Data Sources}
    \begin{enumerate}
        \item \textbf{Structured Data}
        \begin{itemize}
            \item Organized, follows a pre-defined model
            \item Examples: SQL databases, spreadsheets, CRM systems
            \item Usage: Best for regression and classification tasks
        \end{itemize}
        
        \item \textbf{Unstructured Data}
        \begin{itemize}
            \item Does not fit a traditional structure (textual or multimedia)
            \item Examples: Social media posts, emails, images
            \item Usage: Essential for NLP and image recognition tasks
        \end{itemize}
        
        \item \textbf{Semi-Structured Data}
        \begin{itemize}
            \item Some organizational properties but not strict schema
            \item Examples: JSON files, XML documents
            \item Usage: Web data extraction, APIs
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Real-World Data Sources and Their Importance}
    \begin{block}{Real-World Data Sources}
        \begin{itemize}
            \item \textbf{Public Datasets:} Kaggle, UCI Repository, government databases
            \item \textbf{Web Scraping:} Automated extraction from websites
            \item \textbf{IoT Devices:} Data gathered from smart sensors in various domains
        \end{itemize}
    \end{block}

    \begin{block}{Importance in ML}
        \begin{itemize}
            \item \textbf{Diversity and Representation:} Reduces bias in models
            \item \textbf{Volume and Variety:} Enhances model learning and performance
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Example: Customer Segmentation}
    Imagine a retail company wanting to optimize its marketing strategy. By integrating different data types:
    
    \begin{itemize}
        \item \textbf{Structured Data:} Sales records
        \item \textbf{Unstructured Data:} Customer reviews
        \item \textbf{Semi-Structured Data:} Social media interactions
    \end{itemize}

    The company could build a model that segments customers based on purchasing behavior, leading to targeted marketing campaigns.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points to Remember}
    \begin{itemize}
        \item \textbf{Data Quality Matters:} The collection method impacts model accuracy.
        \item \textbf{Integration of Different Sources:} Combining data types often yields better results.
        \item \textbf{Ethics and Privacy:} Always consider implications of data use, especially from personal sources.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data-Driven Solutions in Practice - Introduction}
    In this section, we explore how fundamental machine learning (ML) models are harnessed to solve real-world problems. 
    \begin{itemize}
        \item By examining case studies, we can discern the practical applications of ML algorithms.
        \item Highlighting their effectiveness and transformative potential across various industries.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data-Driven Solutions in Practice - Key Concepts}
    \begin{itemize}
        \item \textbf{Machine Learning Models} 
            \begin{itemize}
                \item Basic ML models: decision trees, linear regression, logistic regression, k-nearest neighbors.
                \item Reliance on data to learn patterns and make predictions.
            \end{itemize}
        \item \textbf{Data-Driven Approach}
            \begin{itemize}
                \item Efficacy depends on the quality and quantity of data.
                \item Real-world case studies demonstrate meaningful insights and solutions.
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data-Driven Solutions in Practice - Case Study Examples}
    \begin{enumerate}
        \item \textbf{Healthcare Diagnostics}
            \begin{itemize}
                \item \textbf{Problem:} Early disease detection improves outcomes and reduces costs.
                \item \textbf{Solution:} Logistic regression models predict disease likelihood.
                \item \textbf{Impact:} 20\% increase in early diagnoses and timely interventions.
            \end{itemize}
        \item \textbf{Retail Inventory Management}
            \begin{itemize}
                \item \textbf{Problem:} Inventory mismanagement leads to stockouts or overstock.
                \item \textbf{Solution:} Decision trees predict demand based on historical data.
                \item \textbf{Impact:} 30\% reduction in excess inventory and a 15\% increase in sales.
            \end{itemize}
        \item \textbf{Financial Fraud Detection}
            \begin{itemize}
                \item \textbf{Problem:} Financial institutions face risks from fraudulent transactions.
                \item \textbf{Solution:} K-nearest neighbors identify outlier behaviors indicating fraud.
                \item \textbf{Impact:} 40\% reduction in fraudulent transactions.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data-Driven Solutions in Practice - Key Points and Conclusion}
    \begin{itemize}
        \item \textbf{Adaptability of Models:} Basic ML models can address various problems across sectors.
        \item \textbf{Importance of Data Quality:} High-quality data is crucial for successful ML applications.
        \item \textbf{Real-World Impact:} Technologies lead to positive changes in lives and businesses.
    \end{itemize}
    
    \textbf{Conclusion:} The integration of ML models into everyday challenges shows the profound impact of data-driven solutions. We will also explore ethical considerations in future discussions.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data-Driven Solutions in Practice - Questions for Reflection}
    \begin{itemize}
        \item How might the choice of model impact the outcomes?
        \item What are some potential challenges in implementing these ML solutions?
        \item In what other areas can we see similar applications of basic ML models?
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Ethical Considerations in AI}
    \begin{block}{Introduction}
        As Artificial Intelligence (AI) influences various aspects of life, it is important to address ethical considerations for responsible and fair data use. This slide discusses main ethical issues surrounding AI, focusing on \textbf{bias} and \textbf{privacy}.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Ethical Concerns}
    \begin{enumerate}
        \item \textbf{Bias in AI}
        \begin{itemize}
            \item \textbf{Definition}: Systematic favoritism or prejudice affecting decision-making in AI models.
            \item \textbf{Example}: An AI hiring tool trained on predominantly white candidates may discriminate against diverse applicants, known as algorithmic bias.
            \item \textbf{Illustration}: A pie chart showing demographic imbalances in training datasets.
        \end{itemize}
        
        \item \textbf{Privacy Issues}
        \begin{itemize}
            \item \textbf{Definition}: Concerns arise when AI systems handle sensitive personal information without proper consent.
            \item \textbf{Example}: Health apps collecting user data that may be shared without transparency can compromise privacy.
            \item \textbf{Illustration}: A data flow diagram showcasing data movement and privacy bottlenecks.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Core Principles for Ethical AI Development}
    \begin{enumerate}
        \item \textbf{Transparency}: Ensure AI systems are understandable, fostering trust and accountability.
        \item \textbf{Fairness}: Strive to eliminate biases, using diverse datasets and conducting regular audits.
        \item \textbf{Accountability}: Establish clear accountability measures for AI use and consequences of failures.
        \item \textbf{User Consent}: Obtain explicit consent from users before collecting data and inform them of its use.
    \end{enumerate}

    \begin{block}{Conclusion}
        Prioritizing ethical considerations in AI fosters trust and acceptance. By proactively addressing bias and privacy, we can enhance the positive impact of AI technologies.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion - Understanding Basic Machine Learning Models}
    % Overview of importance of basic ML models
    As we conclude our exploration of basic ML models, it is vital to recognize their significance in both theoretical and practical contexts. These foundational concepts play a crucial role in the advancement of complex algorithms that shape our world today.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion - Key Points to Emphasize}
    \begin{enumerate}
        \item \textbf{Foundation for Advanced Models:}  
        Mastering basic ML models like linear regression and decision trees is essential for understanding more advanced techniques such as neural networks and ensemble methods.
        
        \item \textbf{Real-World Applications:}  
        These models are applied across different industries. Notable examples include:
        \begin{itemize}
            \item \textbf{Healthcare:} Predicting patient outcomes using logistic regression.
            \item \textbf{Finance:} Assessing credit risk with decision trees.
            \item \textbf{Retail:} Enhancing customer experience via clustering algorithms.
        \end{itemize}
        
        \item \textbf{Data Literacy:}  
        Understanding basic ML models helps interpret results, enabling effective data-driven decision-making.
        
        \item \textbf{Ethical Considerations:}  
        Awareness of model bias ensures fairness and transparency in AI applications.
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion - Engaging Reflection Questions}
    \begin{itemize}
        \item How might a basic understanding of machine learning improve decision-making in your future career?
        \item In what ways can simplicity in model choice lead to significant impacts in solving complex problems?
        \item Can you think of a scenario where the misuse of a basic ML model could lead to unintended consequences? How might you prevent this?
    \end{itemize}

    \begin{block}{Closing Thought}
        As you advance in machine learning, remember that these foundational models are not just algorithms; they are powerful tools for innovation, efficiency, and societal change. Keep exploring and connect these concepts with real-world challenges.
    \end{block}
\end{frame}


\end{document}